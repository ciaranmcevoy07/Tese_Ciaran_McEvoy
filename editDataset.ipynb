{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import dateutil.parser\n",
    "from scipy.io import savemat\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import numpy.random as rng\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.utils import shuffle\n",
    "import nibabel as nib #reading MR images\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESURFER_A_USAR = 'freesurfer_cross_long_a_usar.csv'\n",
    "ASEG_STATS = 'aseg_stats.csv'\n",
    "LIPIDOMICS = 'lipidomics_v3.csv'\n",
    "NAO_PROCESSADOS = 'nao_processados_a_usar_melhores_expandido.csv'\n",
    "DATASET = 'DatasetPro4.0.csv'\n",
    "MMSE = 'MMSE.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes= pd.read_csv('rh_aparc.DKTatlas_stats.csv')\n",
    "# lipidomics = pd.read_csv('D:\\Tese\\lipidomics_v3.csv')\n",
    "\n",
    "rid = []\n",
    "viscode = []\n",
    "for index, row in volumes.iterrows():\n",
    "    match = re.search(r\"S_0?(.*?)\\.\", row['rh.aparc.DKTatlas.volume']).group(1)\n",
    "    match2 = re.search(r\"\\.(.*?)$\", row['rh.aparc.DKTatlas.volume']).group(1)\n",
    "    rid.append(match)\n",
    "    viscode.append(match2)\n",
    "volumes.pop('rh.aparc.DKTatlas.volume')\n",
    "volumes.insert(0, 'RID', rid)\n",
    "volumes.insert(1, 'VISCODE', viscode)\n",
    "volumes.to_csv('rh_aparc.DKTatlas_stats1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list= pd.read_csv('D:\\Tese\\SubjectList.csv')\n",
    "dataset11= pd.read_csv('D:\\Tese\\Dataset_Final\\Dataset1.1.csv')\n",
    "\n",
    "age = []\n",
    "sex = []\n",
    "date = []\n",
    "group = []\n",
    "for index1, row1 in dataset11.iterrows():\n",
    "    for index2, row2 in subject_list.iterrows():\n",
    "        if (row1['RID'] == row2['RID']) and (row1['VISCODE'] == row2['VISCODE']):\n",
    "            age.append(row2['Age'])\n",
    "            sex.append(row2['Sex'])\n",
    "            date.append(row2['Acq Date'])\n",
    "            group.append(row2['Group'])\n",
    "dataset11.insert(2, 'Age', age)\n",
    "dataset11.insert(3, 'Sex', sex)\n",
    "dataset11.insert(4, 'MRI_Date', date)\n",
    "dataset11.insert(5, 'Group', group)\n",
    "dataset11.to_csv('Dataset1.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12= pd.read_csv('D:\\Tese\\Dataset_Final\\Dataset1.2.csv')\n",
    "lipidomics = pd.read_csv('D:\\Tese\\lipidomics_v3.csv')\n",
    "\n",
    "dataset13 = pd.merge(dataset12, lipidomics, on=['RID', 'VISCODE'], how='inner')\n",
    "dataset13 = dataset13.drop_duplicates(subset=['RID', 'VISCODE'])\n",
    "lipidomics_date = dataset13.pop('EXAMDATE')\n",
    "viscode2 = dataset13.pop('VISCODE2')\n",
    "dataset13.insert(6, 'EXAMDATE', lipidomics_date)\n",
    "dataset13.insert(7, 'VISCODE2', viscode2)\n",
    "dataset13 = dataset13.sort_values(by=['RID', 'MRI_Date'], ascending=[True, True])\n",
    "dataset13.to_csv('Dataset1.3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('merged.csv')\n",
    "merged = merged.sort_values(by=['RID', 'Exam_Date'], ascending=[True, True])\n",
    "merged.to_csv('merged_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('DatasetPro6.0.csv')\n",
    "rh= pd.read_csv('rh_aparc.DKTatlas_stats.csv')\n",
    "lh= pd.read_csv('lh_aparc.DKTatlas_stats.csv')\n",
    "merged_aparc = pd.merge(rh, lh, on=['RID', 'VISCODE'], how='inner')\n",
    "merged_aparc = merged_aparc.drop(columns=['BrainSegVolNotVent_x', 'eTIV_x', 'BrainSegVolNotVent_y', 'eTIV_y'])\n",
    "merged_df = pd.merge(dataset, merged_aparc, on=['RID', 'VISCODE'], how='inner')\n",
    "merged_df.to_csv('DatasetPro7.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('DatasetPro7.0.csv')\n",
    "count = 0\n",
    "for col in dataset.columns[1639:1704]:\n",
    "    term = dataset.pop(col)\n",
    "    dataset.insert(9+count, col, term)\n",
    "    count +=1\n",
    "dataset.to_csv('DatasetPro8.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Intracranial Volume Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET)\n",
    "dataset['LHC_ICV'] = None\n",
    "dataset['RHC_ICV'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "        l = round(row['Left-Hippocampus']/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        r = round(row['Right-Hippocampus']/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        dataset.at[index, 'LHC_ICV'] = l\n",
    "        dataset.at[index, 'RHC_ICV'] = r\n",
    "        print(dataset.loc[index, 'RID'])\n",
    "\n",
    "dataset.to_csv('DatasetPro2.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MMSE Values to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('DatasetPro2.0.csv')\n",
    "mmse = pd.read_csv(MMSE)\n",
    "dataset['MMSE'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    for index2, row2 in mmse.iterrows():\n",
    "        if (row['RID'] == row2['RID']) and (row['VISCODE2'] == row2['VISCODE2']):\n",
    "            dataset.at[index, 'MMSE'] = row2['MMSCORE']\n",
    "            print(dataset.loc[index, 'RID'])\n",
    "dataset.to_csv('DatasetPro3.0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacao de Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('DatasetPro8.0.csv')\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    for i in dataset.columns[9:132]:\n",
    "        value = round(row[i]/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        new_col = i+'_ICV'\n",
    "        dataset.at[index, new_col] = value\n",
    "dataset.to_csv('DatasetPro9.0.csv', index=False)  \n",
    "\n",
    "\n",
    "# print(dataset.columns[9:132])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacao de Lipidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'DatasetPro3.0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET)\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    total = row[dataset.columns[74:855]].sum()\n",
    "    for i in dataset.columns[74:855]:\n",
    "        new_col = i+'%mol'\n",
    "        perc_mol = (row[i]/total) * 100\n",
    "        dataset.at[index, new_col] = perc_mol\n",
    "dataset.to_csv('DatasetPro4.0.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMSE Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AD', 'MCI', 'CN', 'EMCI', 'LMCI', 'SMC']\n",
      "22.0 26.0 29.0 29.0 26.0 29.0\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'DatasetPro5.0.csv'\n",
    "dataset = pd.read_csv(DATASET)\n",
    "\n",
    "group_items = []\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Group'] not in group_items:\n",
    "        group_items.append(row['Group'])\n",
    "print(group_items)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "valuesAD = dataset.loc[dataset['Group'] == 'AD', 'MMSE'].tolist()\n",
    "ad = [x for x in valuesAD if not np.isnan(x)]\n",
    "median_value_ad = statistics.median(ad)\n",
    "\n",
    "valuesMCI = dataset.loc[dataset['Group'] == 'MCI', 'MMSE'].tolist()\n",
    "mci = [x for x in valuesMCI if not np.isnan(x)]\n",
    "median_value_mci = statistics.median(mci)\n",
    "\n",
    "valuesCN = dataset.loc[dataset['Group'] == 'CN', 'MMSE'].tolist()\n",
    "cn = [x for x in valuesCN if not np.isnan(x)]\n",
    "median_value_cn = statistics.median(cn)\n",
    "\n",
    "valuesEMCI = dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'].tolist()\n",
    "emci = [x for x in valuesEMCI if not np.isnan(x)]\n",
    "median_value_emci = statistics.median(emci)\n",
    "\n",
    "valuesLMCI = dataset.loc[dataset['Group'] == 'LMCI', 'MMSE'].tolist()\n",
    "lmci = [x for x in valuesLMCI if not np.isnan(x)]\n",
    "median_value_lmci = statistics.median(lmci)\n",
    "\n",
    "valuesSMC = dataset.loc[dataset['Group'] == 'SMC', 'MMSE'].tolist()\n",
    "smc = [x for x in valuesSMC if not np.isnan(x)]\n",
    "median_value_smc = statistics.median(smc)\n",
    "\n",
    "print(median_value_ad,median_value_mci,median_value_cn,median_value_emci,median_value_lmci,median_value_smc)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "dataset.loc[dataset['Group'] == 'AD', 'MMSE'] = dataset.loc[dataset['Group'] == 'AD', 'MMSE'].fillna(median_value_ad)\n",
    "dataset.loc[dataset['Group'] == 'MCI', 'MMSE'] = dataset.loc[dataset['Group'] == 'MCI', 'MMSE'].fillna(median_value_mci)\n",
    "dataset.loc[dataset['Group'] == 'CN', 'MMSE'] = dataset.loc[dataset['Group'] == 'CN', 'MMSE'].fillna(median_value_cn)\n",
    "dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'] = dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'].fillna(median_value_emci)\n",
    "dataset.loc[dataset['Group'] == 'lmci', 'MMSE'] = dataset.loc[dataset['Group'] == 'lmci', 'MMSE'].fillna(median_value_lmci)\n",
    "dataset.loc[dataset['Group'] == 'SMC', 'MMSE'] = dataset.loc[dataset['Group'] == 'SMC', 'MMSE'].fillna(median_value_smc)\n",
    "dataset.to_csv('DatasetPro6.0.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Lipid Class Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SPH.D18.1.%mol', 'SPH.D18.2.%mol', 'S1P.D16.1.%mol', 'S1P.D18.0.%mol',\n",
      "       'S1P.D18.1.%mol', 'S1P.D18.2.%mol', 'DHCER.D18.0.16.0.%mol',\n",
      "       'DHCER.D18.0.18.0.%mol', 'DHCER.D18.0.20.0.%mol',\n",
      "       'DHCER.D18.0.22.0.%mol',\n",
      "       ...\n",
      "       'TG.O.54.4...NL.18.2.%mol', 'UBIQUINONE%mol', 'CE.18.2....OH.%mol',\n",
      "       'CE.20.4....OH.%mol', 'CE.22.6....OH.%mol', 'LPC.18.2....OH.%mol',\n",
      "       'LPC.20.4....OH.%mol', 'LPC.22.6....OH.%mol', 'PC.34.2....OH.%mol',\n",
      "       'PC.36.4....OH.%mol'],\n",
      "      dtype='object', length=781)\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'DatasetPro9.0.csv'\n",
    "dataset = pd.read_csv(DATASET)\n",
    "features = []\n",
    "for feature in dataset.columns[923:1703]:\n",
    "    match = re.search(r'^[^.]+', feature)\n",
    "    i = match.group(0)\n",
    "    if i not in features:\n",
    "        features.append(i)\n",
    "\n",
    "swap_dict = {\n",
    "    'CA%mol': 'CA',\n",
    "    'DXCA%mol': 'DXCA',\n",
    "    'COH%mol': 'COH',\n",
    "    'UBIQUINONE%mol': 'UBIQUINONE'\n",
    "}\n",
    "features = [swap_dict.get(item, item) for item in features]\n",
    "print(features)\n",
    " \n",
    "dataset.drop(columns=dataset.columns[141:922], inplace=True)\n",
    "\n",
    "for feature in features:\n",
    "    feature_sum = []\n",
    "    matched_columns = [col for col in dataset.columns[141:922] if re.search(feature, col)]\n",
    "    if matched_columns:\n",
    "        feature_sum = dataset[matched_columns].sum(axis=1)\n",
    "    else:\n",
    "        feature_sum = [0] * len(dataset)\n",
    "    dataset[feature] = feature_sum\n",
    "\n",
    "dataset.to_csv('DatasetPro10.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 29, 287, 636, 685, 710, 752, 965, 1229, 1230, 1339, 1547, 1830, 2077, 2102, 2658, 2713, 22, 24, 25, 28, 114, 227, 228, 606, 608, 609, 610, 654, 655, 843, 1237, 1239, 1502, 1545, 1546, 1837, 1875, 1876, 1881, 1927, 1942, 1951, 1952, 2041, 2042, 2086, 2094, 2113, 2115, 2138, 2159, 2160, 2161, 2166, 2189, 2197, 2204, 2207, 2208, 2225, 2227, 2255, 2296, 2321, 2322, 2331, 2375, 2401, 2431, 2439, 2536, 2602, 2603, 2612, 2634, 2684, 2726, 2739, 21, 22, 26, 542, 936, 1247, 1400, 1407, 1821, 1866, 1875, 1876, 2038, 2039, 2059, 2060, 2086, 2138, 2189, 2197, 2214, 2255, 2290, 2568, 2572, 2576, 2593, 2603, 2627, 2659, 2691, 5, 8, 64, 104, 112, 113, 153, 170, 171, 172, 201, 214, 249, 412, 470, 641, 649, 704, 706, 733, 897, 902, 936, 937, 941, 1730, 1765, 1781, 1782, 1783, 1805, 1816, 1817, 2063, 2064, 2083, 2315, 2340, 2481, 2538, 757, 848, 849, 850, 851, 928, 929, 932, 1137, 1267, 1540, 1547, 1548, 1715, 1716, 1764, 1766, 1891, 1951, 1952, 1965, 1994, 2037, 2080, 2128, 2141, 2244, 2245, 2291, 2298, 2327, 2412, 2413, 2478, 2479, 2538, 2593, 2624, 2691, 2704, 10, 186, 201, 932, 1266, 1267, 1269, 1400, 1500, 1623, 1624, 1625, 1715, 1764, 1983, 2083, 2101, 2141, 2153, 2154, 2195, 2244, 2296, 2442, 2478, 2479, 2554, 2584, 2590, 2704, 2717, 215, 250, 340, 642, 880, 940, 965, 966, 967, 1137, 1250, 1765, 1782, 1783, 2231, 2705, 2719, 238, 291, 529, 587, 598, 623, 791, 880, 1131, 1213, 1339, 1340, 1341, 1400, 1401, 1716, 1728, 1730, 1731, 1765, 1766, 1801, 1802, 1829, 1830, 4, 6, 47, 48, 70, 71, 172, 174, 663, 1096, 1164, 1165, 1371, 1400, 1512, 1541, 1641, 1730, 1770, 1817, 1983, 2141, 2170, 2244, 2442, 2554, 2584, 2643, 337, 339, 340, 786, 872, 878, 897, 899, 994, 996, 1201, 1341, 1348, 1363, 1484, 1542, 1680, 1689, 1765, 1781, 1783, 1801, 1807, 1864, 1951, 2063, 2064, 2071, 2080, 2083, 2102, 2230, 2231, 2270, 2369, 2443, 2519, 2559, 2718, 747, 1416, 2197, 2318, 2357, 2719, 132, 172, 419, 451, 452, 453, 494, 513, 664, 693, 752, 902, 1230, 1250, 1484, 1492, 1501, 1504, 1629, 1630, 1769, 1781, 1782, 1783, 1897, 1898, 1999, 2025, 2031, 2043, 2044, 2072, 2083, 2087, 2094, 2095, 2118, 2136, 2138, 2172, 2205, 2370, 2443, 2474, 2496, 2506, 2511, 2514, 2618, 2634, 2644, 2656, 2660, 2703, 122, 653, 747, 872, 879, 911, 912, 1045, 1212, 1372, 1541, 1807, 2011, 2016, 2017, 2136, 2475, 2559, 2608, 13, 38, 104, 121, 122, 167, 223, 225, 250, 354, 494, 692, 693, 752, 770, 902, 942, 1001, 1043, 1045, 1060, 1062, 1094, 1095, 1106, 1123, 1185, 1492, 1497, 1504, 1541, 1769, 1830, 1927, 1999, 2011, 2016, 2017, 2086, 2136, 2184, 2607, 2608, 451, 453, 454, 455, 608, 641, 1046, 1246, 1372, 1427, 1502, 1541, 1748, 2014, 2015, 2038, 2207, 2322, 2323, 2324, 2375, 2388, 2409, 2475, 2602, 2618, 2693, 514, 617, 694, 695, 860, 862, 899, 911, 912, 1001, 1047, 1060, 1062, 1485, 1486, 1504, 1829, 1830, 2017, 2077, 2078, 2136, 2138, 2184, 2205, 2322, 2499, 2559, 2594, 63, 663, 671, 835, 861, 1120, 1208, 1240, 1516, 1665, 1669, 1744, 1745, 1771, 1772, 1782, 1927, 2073, 2083, 2110, 2136, 2137, 2183, 2204, 2281, 2426, 2427, 2536, 2602, 2659, 2665, 267, 296, 303, 304, 902, 1001, 1558, 1978, 2089, 2163, 2164, 2182, 2183, 2192, 2199, 2207, 2225, 2244, 2253, 2264, 2268, 2273, 2290, 2295, 2298, 2299, 2300, 2303, 2327, 2339, 2340, 2349, 2357, 2367, 2379, 2392, 2399, 2401, 2404, 2406, 2410, 2411, 2417, 2423, 2424, 2426, 2436, 2437, 2438, 2439, 2440, 2443, 2460, 2461, 2476, 2477, 2478, 2479, 2482, 2491, 2501, 2506, 2511, 2512, 2514, 2660, 2684, 2714, 27, 35, 62, 64, 81, 83, 89, 167, 246, 287, 291, 606, 608, 710, 711, 901, 912, 934, 1060, 1131, 1140, 1142, 1186, 1246, 1250, 1502, 1549, 1623, 1624, 1805, 1806, 1807, 1814, 2094, 2097, 2204, 2235, 2370, 2371, 2612, 29, 101, 128, 267, 287, 710, 852, 868, 902, 968, 1047, 1094, 1096, 1120, 1229, 1230, 1367, 1371, 1421, 1492, 1558, 1629, 1630, 1740, 1951, 2007, 2008, 2053, 2054, 2077, 2087, 2089, 2128, 2141, 2161, 2192, 2236, 2276, 2295, 2370, 2443, 2466, 2515, 2554, 2644, 2658, 2660, 2672, 2710, 2749, 126, 133, 255, 312, 313, 369, 515, 517, 776, 805, 858, 859, 1045, 1115, 1358, 1560, 1562, 1665, 1669, 1672, 1673, 1734, 1771, 1865, 1866, 1923, 1928, 1942, 2014, 2015, 2041, 2086, 2094, 2119, 2136, 2137, 2180, 2189, 2205, 2251, 2275, 2296, 2322, 2329, 2375, 2399, 2402, 2403, 2485, 2489, 2496, 2499, 2500, 2518, 2602, 2603, 2742, 123, 132, 133, 187, 312, 517, 606, 616, 618, 653, 654, 747, 787, 1113, 1115, 1406, 1414, 1416, 1546, 1672, 1673, 1771, 2086, 2094, 2138, 2189, 2205, 2375, 2402, 2489, 2602, 2603, 2607, 2608, 17, 47, 62, 494, 548, 747, 849, 1153, 1362, 1504, 1605, 1782, 1815, 1844, 2197, 2210, 2231, 2318, 2478, 2571, 2692, 583, 868, 871, 872, 873, 994, 1268, 1315, 1323, 1429, 1765, 1817, 1993, 1994, 2016, 2017, 2063, 2064, 2090, 2091, 2107, 2108, 2173, 2176, 2214, 2227, 2255, 2294, 2440, 2443, 2469, 2514, 2515, 2530, 2554, 2704, 2717, 2718, 2751, 23, 119, 216, 283, 285, 287, 328, 408, 432, 467, 469, 524, 637, 638, 769, 770, 832, 833, 868, 871, 872, 873, 911, 912, 913, 918, 919, 994, 1012, 1013, 1014, 1041, 1042, 1043, 1044, 1048, 1049, 1050, 1060, 1128, 1129, 1130, 1131, 1132, 1153, 1239, 1240, 1281, 1315, 1322, 1323, 1366, 1368, 1371, 1400, 1401, 1461, 1515, 1540, 1567, 1632, 1633, 1764, 1765, 1766, 1817, 1865, 1871, 1952, 1993, 2016, 2017, 2029, 2030, 2063, 2064, 2091, 2116, 2117, 2155, 2173, 2176, 2177, 2203, 2213, 2214, 2227, 2230, 2237, 2299, 2315, 2332, 2358, 2370, 2391, 2433, 2434, 2442, 2443, 2483, 2484, 2491, 2492, 2505, 2506, 2514, 2515, 2529, 2530, 2542, 2574, 2593, 2631, 2658, 2695, 2704, 2718, 97, 190, 192, 196, 212, 446, 470, 471, 670, 939, 940, 941, 1185, 1495, 1541, 1629, 1781, 1805, 1806, 1984, 1985, 2016, 2017, 2224, 2230, 2231, 2269, 2292, 2293, 2360, 2409, 2417, 2431, 2501, 2502, 2503, 2587, 2588, 2589, 2624, 2625, 2627, 2704, 2726, 97, 98, 190, 191, 192, 196, 446, 470, 471, 670, 939, 940, 941, 1165, 1805, 1985, 2016, 2017, 2230, 2231, 2292, 2293, 2360, 2409, 2431, 2466, 2501, 2502, 2503, 2563, 2587, 2588, 2589, 2624, 2627, 2726, 26, 36, 494, 562, 563, 587, 609, 645, 1047, 1134, 1136, 1386, 1706, 1808, 1973, 2023, 2098, 2099, 2100, 2364, 2368, 2389, 2411, 2423, 2432, 2491, 2492, 2558, 2567, 2644, 2690, 2722, 38, 228, 238, 250, 281, 282, 340, 691, 939, 941, 1010, 1011, 1229, 1253, 1266, 1267, 1276, 1319, 1386, 1557, 1581, 1627, 1710, 1805, 1815, 1865, 2015, 2086, 2098, 2211, 2336, 2434, 2557, 2573, 2575, 2643, 8, 40, 91, 99, 121, 166, 167, 168, 170, 171, 187, 195, 196, 197, 198, 207, 214, 215, 287, 316, 319, 353, 387, 389, 392, 409, 410, 503, 513, 514, 536, 551, 552, 554, 598, 599, 600, 608, 611, 627, 635, 653, 654, 655, 702, 703, 720, 735, 736, 737, 751, 752, 753, 777, 799, 850, 853, 854, 856, 858, 872, 927, 928, 929, 930, 931, 932, 982, 994, 1020, 1043, 1062, 1114, 1187, 1190, 1206, 1213, 1239, 1246, 1250, 1258, 1259, 1276, 1290, 1306, 1349, 1357, 1371, 1373, 1385, 1389, 1492, 1495, 1498, 1550, 1558, 1559, 1579, 1634, 1731, 1739, 1765, 1768, 1770, 1773, 1841, 1871, 1876, 1907, 1927, 2009, 2014, 2017, 2029, 2032, 2036, 2037, 2042, 2052, 2053, 2071, 2074, 2075, 2081, 2094, 2097, 2098, 2100, 2109, 2113, 2139, 2163, 2204, 2210, 2226, 2227, 2235, 2247, 2268, 2297, 2339, 2340, 2367, 2368, 2404, 2405, 2409, 2410, 2436, 2440, 2443, 2461, 2475, 2477, 2479, 2496, 2518, 2521, 2537, 2552, 2563, 2568, 2618, 2661, 2684, 2699, 2734, 2749, 40, 84, 99, 166, 168, 171, 303, 305, 316, 319, 353, 513, 514, 536, 611, 653, 654, 655, 702, 735, 736, 751, 752, 856, 858, 867, 872, 927, 931, 994, 996, 1043, 1062, 1114, 1187, 1190, 1213, 1250, 1270, 1290, 1349, 1357, 1385, 1469, 1550, 1579, 1634, 1731, 1739, 1764, 1765, 1766, 1768, 1773, 1865, 1871, 1909, 2014, 2016, 2017, 2032, 2036, 2052, 2053, 2074, 2100, 2109, 2113, 2163, 2184, 2216, 2226, 2227, 2235, 2247, 2248, 2340, 2367, 2368, 2391, 2410, 2461, 2477, 2479, 2496, 2518, 2521, 2522, 2537, 2552, 2568, 2574, 2618, 2684, 2749, 132, 133, 398, 434, 494, 515, 516, 517, 606, 638, 654, 711, 713, 1235, 1239, 1240, 1244, 1406, 1414, 1415, 1416, 1504, 1546, 1560, 1561, 1562, 1601, 1602, 1605, 1635, 1672, 1771, 1772, 1942, 1998, 1999, 2039, 2058, 2086, 2094, 2138, 2144, 2180, 2189, 2204, 2205, 2207, 2215, 2226, 2251, 2282, 2375, 2399, 2402, 2403, 2489, 2512, 2518, 2531, 2602, 2603, 2607, 2608, 2, 124, 132, 133, 312, 318, 398, 434, 476, 517, 616, 618, 653, 654, 655, 747, 799, 869, 1115, 1179, 1180, 1181, 1406, 1414, 1416, 1546, 1672, 1673, 1771, 2205, 2275, 2402, 2489, 63, 190, 192, 240, 241, 242, 275, 334, 356, 357, 358, 362, 452, 453, 710, 786, 922, 923, 957, 980, 1140, 1141, 1142, 1143, 1144, 1171, 1172, 1173, 1174, 1239, 1240, 1267, 1268, 1269, 1271, 1272, 1291, 1415, 1434, 1435, 1512, 1541, 1574, 1575, 1671, 1951, 2031, 2053, 2145, 2165, 2255, 2304, 2327, 2377, 2379, 2380, 2435, 2501, 2507, 2531, 2554, 2625, 2627, 2688]\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"Statistics/test/TempDatasetPro10.csv\"\n",
    "dataset = pd.read_csv(DATASET)\n",
    "# filtered_rows = dataset[(dataset['Age'] > 70) & (dataset['Group'] == \"MCI\")]\n",
    "df_filtered = dataset.drop(dataset[(dataset['Age'] > 70) & (dataset['Group'] == \"MCI\")].index)\n",
    "\n",
    "def outliers(df,ft):\n",
    "    Q1 = df[ft].quantile(0.25)\n",
    "    Q3 = df[ft].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    ls = df.index[(df[ft] < lower_bound) | (df[ft] > upper_bound)]\n",
    "\n",
    "    return ls\n",
    "\n",
    "index_list = []\n",
    "for feature in df_filtered.columns[1046:1080]:\n",
    "    index_list.extend(outliers(df_filtered, feature))\n",
    "print(index_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SPH       S1P     DHCER       CER     CER1P    HEXCER   HEX2CER  \\\n",
      "494   0.003019  0.007524  0.006396  0.195131  0.000067  0.016439  0.011915   \n",
      "606   0.001747  0.014221  0.021064  0.243990  0.000048  0.021507  0.010307   \n",
      "618   0.000469  0.008508  0.010436  0.317340  0.000030  0.013024  0.012117   \n",
      "872   0.000770  0.016696  0.006526  0.320566  0.000128  0.050735  0.031469   \n",
      "902   0.004640  0.009545  0.007609  0.266929  0.000217  0.045912  0.031250   \n",
      "1416  0.000585  0.008275  0.009276  0.294153  0.000036  0.015181  0.012266   \n",
      "1765  0.001010  0.018560  0.008006  0.369854  0.000211  0.054222  0.037921   \n",
      "1771  0.000396  0.008010  0.008535  0.232823  0.000051  0.013849  0.008396   \n",
      "1805  0.000921  0.018137  0.006261  0.279382  0.000222  0.037285  0.030451   \n",
      "1865  0.001430  0.017147  0.011003  0.358471  0.000072  0.028518  0.011824   \n",
      "1999  0.003392  0.023957  0.008763  0.229067  0.000057  0.024230  0.012975   \n",
      "2086  0.001664  0.021193  0.013356  0.420266  0.000047  0.028935  0.016693   \n",
      "2094  0.001601  0.017974  0.014135  0.290044  0.000146  0.025986  0.021713   \n",
      "2138  0.000900  0.009792  0.032357  0.465963  0.000065  0.023567  0.023468   \n",
      "2489  0.000896  0.006015  0.009332  0.256370  0.000048  0.021532  0.017812   \n",
      "2602  0.001150  0.012328  0.015456  0.408893  0.000078  0.036778  0.014739   \n",
      "2607  0.001540  0.009992  0.009820  0.310923  0.000021  0.015078  0.017642   \n",
      "\n",
      "       HEX3CER       GM3       GM1  ...    METHYL  DIMETHYL         FA  \\\n",
      "494   0.010705  0.015788  0.000526  ...  0.061330  0.030402  14.337418   \n",
      "606   0.014940  0.019689  0.000685  ...  0.081686  0.038025   7.248501   \n",
      "618   0.015296  0.029955  0.000588  ...  0.301128  0.152723   2.195652   \n",
      "872   0.047777  0.046697  0.001538  ...  0.294588  0.124900   6.773777   \n",
      "902   0.036590  0.031690  0.001057  ...  0.264005  0.101639   6.285169   \n",
      "1416  0.011486  0.017356  0.000331  ...  0.054053  0.029713   2.589275   \n",
      "1765  0.053199  0.060256  0.001769  ...  0.176063  0.063245   6.044136   \n",
      "1771  0.010921  0.022314  0.000332  ...  0.094264  0.050841   1.986690   \n",
      "1805  0.048268  0.047469  0.001610  ...  0.664707  0.238274  12.048996   \n",
      "1865  0.015663  0.024660  0.001097  ...  0.294302  0.124501   4.770585   \n",
      "1999  0.012411  0.012856  0.000815  ...  0.181283  0.078200   8.545497   \n",
      "2086  0.021490  0.028460  0.000826  ...  0.038936  0.016868   8.017516   \n",
      "2094  0.017591  0.026653  0.000791  ...  0.107708  0.056158   7.713020   \n",
      "2138  0.015921  0.023120  0.000807  ...  0.120111  0.072333   7.378951   \n",
      "2489  0.014331  0.018045  0.000935  ...  0.041061  0.023367   3.447821   \n",
      "2602  0.017545  0.021285  0.000541  ...  0.095344  0.050859   4.100156   \n",
      "2607  0.011595  0.011894  0.000529  ...  0.114899  0.049204   7.161851   \n",
      "\n",
      "            AC        CA      DXCA         DG         TG  UBIQUINONE  outlier  \n",
      "494   0.006181  0.000048  0.000037   8.036287  20.370971    0.200831       -1  \n",
      "606   0.008636  0.000084  0.000048  10.498100  28.226593    0.280292       -1  \n",
      "618   0.004144  0.000056  0.000020   5.633396  37.110908    0.237170       -1  \n",
      "872   0.013287  0.000537  0.000182   1.306403   7.471550    0.328317       -1  \n",
      "902   0.013976  0.000120  0.000068   5.812854  12.101502    0.366350       -1  \n",
      "1416  0.005109  0.000048  0.000045  10.040416  42.170260    0.210407       -1  \n",
      "1765  0.013862  0.000362  0.000352   2.386738  13.675106    0.169983       -1  \n",
      "1771  0.002213  0.000058  0.000049   7.116966  43.871008    0.134425       -1  \n",
      "1805  0.025036  0.000033  0.000016   1.753568   8.646210    0.330357       -1  \n",
      "1865  0.026233  0.000227  0.000189   6.859446  24.470288    0.164765       -1  \n",
      "1999  0.008667  0.000046  0.000023   9.161219  23.922980    0.077960       -1  \n",
      "2086  0.022166  0.000089  0.000065  11.373514  21.739862    0.361873       -1  \n",
      "2094  0.013166  0.000258  0.000117   9.552946  24.795408    0.231844       -1  \n",
      "2138  0.007409  0.000045  0.000027  12.490572  24.780963    0.198827       -1  \n",
      "2489  0.005184  0.000055  0.000043   7.605467  44.671135    0.180362       -1  \n",
      "2602  0.008601  0.000078  0.000065  14.036028  28.031341    0.093233       -1  \n",
      "2607  0.005105  0.000094  0.000074  17.172310  24.525642    0.137334       -1  \n",
      "\n",
      "[17 rows x 36 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciara\\anaconda3\\envs\\Monai\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"Statistics/test/TempDatasetPro10.csv\"\n",
    "dataset = pd.read_csv(DATASET)\n",
    "# filtered_rows = dataset[(dataset['Age'] > 70) & (dataset['Group'] == \"MCI\")]\n",
    "df_filtered = dataset.drop(dataset[(dataset['Age'] > 70) & (dataset['Group'] == \"MCI\")].index)\n",
    "df_filtered = df_filtered.iloc[:, 1045:1080]\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "\n",
    "# Fit the model and predict outliers\n",
    "outliers = iso_forest.fit_predict(df_filtered)\n",
    "\n",
    "# Mark outliers\n",
    "df_filtered['outlier'] = outliers\n",
    "\n",
    "# Print the rows classified as outliers\n",
    "print(df_filtered[df_filtered['outlier'] == -1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
