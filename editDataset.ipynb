{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import dateutil.parser\n",
    "from scipy.io import savemat\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import numpy.random as rng\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.utils import shuffle\n",
    "import nibabel as nib #reading MR images\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESURFER_A_USAR = 'freesurfer_cross_long_a_usar.csv'\n",
    "ASEG_STATS = 'aseg_stats.csv'\n",
    "LIPIDOMICS = 'lipidomics_v3.csv'\n",
    "NAO_PROCESSADOS = 'nao_processados_a_usar_melhores_expandido.csv'\n",
    "DATASET = 'DatasetPro4.0.csv'\n",
    "MMSE = 'MMSE.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes= pd.read_csv('rh_aparc.DKTatlas_stats.csv')\n",
    "# lipidomics = pd.read_csv('D:\\Tese\\lipidomics_v3.csv')\n",
    "\n",
    "rid = []\n",
    "viscode = []\n",
    "for index, row in volumes.iterrows():\n",
    "    match = re.search(r\"S_0?(.*?)\\.\", row['rh.aparc.DKTatlas.volume']).group(1)\n",
    "    match2 = re.search(r\"\\.(.*?)$\", row['rh.aparc.DKTatlas.volume']).group(1)\n",
    "    rid.append(match)\n",
    "    viscode.append(match2)\n",
    "volumes.pop('rh.aparc.DKTatlas.volume')\n",
    "volumes.insert(0, 'RID', rid)\n",
    "volumes.insert(1, 'VISCODE', viscode)\n",
    "volumes.to_csv('rh_aparc.DKTatlas_stats1.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list= pd.read_csv('D:\\Tese\\SubjectList.csv')\n",
    "dataset11= pd.read_csv('D:\\Tese\\Dataset_Final\\Dataset1.1.csv')\n",
    "\n",
    "age = []\n",
    "sex = []\n",
    "date = []\n",
    "group = []\n",
    "for index1, row1 in dataset11.iterrows():\n",
    "    for index2, row2 in subject_list.iterrows():\n",
    "        if (row1['RID'] == row2['RID']) and (row1['VISCODE'] == row2['VISCODE']):\n",
    "            age.append(row2['Age'])\n",
    "            sex.append(row2['Sex'])\n",
    "            date.append(row2['Acq Date'])\n",
    "            group.append(row2['Group'])\n",
    "dataset11.insert(2, 'Age', age)\n",
    "dataset11.insert(3, 'Sex', sex)\n",
    "dataset11.insert(4, 'MRI_Date', date)\n",
    "dataset11.insert(5, 'Group', group)\n",
    "dataset11.to_csv('Dataset1.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12= pd.read_csv('D:\\Tese\\Dataset_Final\\Dataset1.2.csv')\n",
    "lipidomics = pd.read_csv('D:\\Tese\\lipidomics_v3.csv')\n",
    "\n",
    "dataset13 = pd.merge(dataset12, lipidomics, on=['RID', 'VISCODE'], how='inner')\n",
    "dataset13 = dataset13.drop_duplicates(subset=['RID', 'VISCODE'])\n",
    "lipidomics_date = dataset13.pop('EXAMDATE')\n",
    "viscode2 = dataset13.pop('VISCODE2')\n",
    "dataset13.insert(6, 'EXAMDATE', lipidomics_date)\n",
    "dataset13.insert(7, 'VISCODE2', viscode2)\n",
    "dataset13 = dataset13.sort_values(by=['RID', 'MRI_Date'], ascending=[True, True])\n",
    "dataset13.to_csv('Dataset1.3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('merged.csv')\n",
    "merged = merged.sort_values(by=['RID', 'Exam_Date'], ascending=[True, True])\n",
    "merged.to_csv('merged_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('DatasetPro6.0.csv')\n",
    "rh= pd.read_csv('rh_aparc.DKTatlas_stats.csv')\n",
    "lh= pd.read_csv('lh_aparc.DKTatlas_stats.csv')\n",
    "merged_aparc = pd.merge(rh, lh, on=['RID', 'VISCODE'], how='inner')\n",
    "merged_aparc = merged_aparc.drop(columns=['BrainSegVolNotVent_x', 'eTIV_x', 'BrainSegVolNotVent_y', 'eTIV_y'])\n",
    "merged_df = pd.merge(dataset, merged_aparc, on=['RID', 'VISCODE'], how='inner')\n",
    "merged_df.to_csv('DatasetPro7.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv('DatasetPro7.0.csv')\n",
    "count = 0\n",
    "for col in dataset.columns[1639:1704]:\n",
    "    term = dataset.pop(col)\n",
    "    dataset.insert(9+count, col, term)\n",
    "    count +=1\n",
    "dataset.to_csv('DatasetPro8.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Intracranial Volume Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET)\n",
    "dataset['LHC_ICV'] = None\n",
    "dataset['RHC_ICV'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "        l = round(row['Left-Hippocampus']/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        r = round(row['Right-Hippocampus']/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        dataset.at[index, 'LHC_ICV'] = l\n",
    "        dataset.at[index, 'RHC_ICV'] = r\n",
    "        print(dataset.loc[index, 'RID'])\n",
    "\n",
    "dataset.to_csv('DatasetPro2.0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MMSE Values to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('DatasetPro2.0.csv')\n",
    "mmse = pd.read_csv(MMSE)\n",
    "dataset['MMSE'] = None\n",
    "for index, row in dataset.iterrows():\n",
    "    for index2, row2 in mmse.iterrows():\n",
    "        if (row['RID'] == row2['RID']) and (row['VISCODE2'] == row2['VISCODE2']):\n",
    "            dataset.at[index, 'MMSE'] = row2['MMSCORE']\n",
    "            print(dataset.loc[index, 'RID'])\n",
    "dataset.to_csv('DatasetPro3.0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacao de Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('DatasetPro8.0.csv')\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    for i in dataset.columns[9:132]:\n",
    "        value = round(row[i]/row['EstimatedTotalIntraCranialVol'],9)\n",
    "        new_col = i+'_ICV'\n",
    "        dataset.at[index, new_col] = value\n",
    "dataset.to_csv('DatasetPro9.0.csv', index=False)  \n",
    "\n",
    "\n",
    "# print(dataset.columns[9:132])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacao de Lipidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'DatasetPro3.0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET)\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    total = row[dataset.columns[74:855]].sum()\n",
    "    for i in dataset.columns[74:855]:\n",
    "        new_col = i+'%mol'\n",
    "        perc_mol = (row[i]/total) * 100\n",
    "        dataset.at[index, new_col] = perc_mol\n",
    "dataset.to_csv('DatasetPro4.0.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMSE Missing Values Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AD', 'MCI', 'CN', 'EMCI', 'LMCI', 'SMC']\n",
      "22.0 26.0 29.0 29.0 26.0 29.0\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'DatasetPro5.0.csv'\n",
    "dataset = pd.read_csv(DATASET)\n",
    "\n",
    "group_items = []\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['Group'] not in group_items:\n",
    "        group_items.append(row['Group'])\n",
    "print(group_items)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "valuesAD = dataset.loc[dataset['Group'] == 'AD', 'MMSE'].tolist()\n",
    "ad = [x for x in valuesAD if not np.isnan(x)]\n",
    "median_value_ad = statistics.median(ad)\n",
    "\n",
    "valuesMCI = dataset.loc[dataset['Group'] == 'MCI', 'MMSE'].tolist()\n",
    "mci = [x for x in valuesMCI if not np.isnan(x)]\n",
    "median_value_mci = statistics.median(mci)\n",
    "\n",
    "valuesCN = dataset.loc[dataset['Group'] == 'CN', 'MMSE'].tolist()\n",
    "cn = [x for x in valuesCN if not np.isnan(x)]\n",
    "median_value_cn = statistics.median(cn)\n",
    "\n",
    "valuesEMCI = dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'].tolist()\n",
    "emci = [x for x in valuesEMCI if not np.isnan(x)]\n",
    "median_value_emci = statistics.median(emci)\n",
    "\n",
    "valuesLMCI = dataset.loc[dataset['Group'] == 'LMCI', 'MMSE'].tolist()\n",
    "lmci = [x for x in valuesLMCI if not np.isnan(x)]\n",
    "median_value_lmci = statistics.median(lmci)\n",
    "\n",
    "valuesSMC = dataset.loc[dataset['Group'] == 'SMC', 'MMSE'].tolist()\n",
    "smc = [x for x in valuesSMC if not np.isnan(x)]\n",
    "median_value_smc = statistics.median(smc)\n",
    "\n",
    "print(median_value_ad,median_value_mci,median_value_cn,median_value_emci,median_value_lmci,median_value_smc)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "dataset.loc[dataset['Group'] == 'AD', 'MMSE'] = dataset.loc[dataset['Group'] == 'AD', 'MMSE'].fillna(median_value_ad)\n",
    "dataset.loc[dataset['Group'] == 'MCI', 'MMSE'] = dataset.loc[dataset['Group'] == 'MCI', 'MMSE'].fillna(median_value_mci)\n",
    "dataset.loc[dataset['Group'] == 'CN', 'MMSE'] = dataset.loc[dataset['Group'] == 'CN', 'MMSE'].fillna(median_value_cn)\n",
    "dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'] = dataset.loc[dataset['Group'] == 'EMCI', 'MMSE'].fillna(median_value_emci)\n",
    "dataset.loc[dataset['Group'] == 'lmci', 'MMSE'] = dataset.loc[dataset['Group'] == 'lmci', 'MMSE'].fillna(median_value_lmci)\n",
    "dataset.loc[dataset['Group'] == 'SMC', 'MMSE'] = dataset.loc[dataset['Group'] == 'SMC', 'MMSE'].fillna(median_value_smc)\n",
    "dataset.to_csv('DatasetPro6.0.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
